{
  "text": " In this module, we will discuss token classification. Thanks to the advancements in language modeling, performing token classification has never been easier and more accurate. In this module, you'll develop hands-on experience with several variations of token classification. We hope that will establish solid understanding of the development workflow so that you can apply it to your own use cases. At this time, I would like to ask you to click on the start button below. This will assign a GPU accelerated cloud instance to you. After the system installation and the configuration completes, you'll be able to launch the hands-on lab. In the meantime, let's preview what you'll learn. This is a good visualization of what token classification can do in the context of macro-language understanding. As an example, name entity recognition and ER, which is a kind of token classification, is used to identify specific entities in a text, such as states, individuals, and places. Generally, token classification can transform unstructured text into structured data for more advanced text analytics. Token classification, like any ER and other tasks, are not just limited to these standard entities. They can be used to identify custom entities based on specific use cases. We can apply the approach to solve difficult problems quickly and efficiently. There are a lot of existing tools that perform token classification with varying degrees of performance. They can also be limited in the type of classification they can perform. So, to truly enable token classification, we need a process that can be generalized. The first token classification model will use consists of a verb model plus a classification layer. In this case, we'll need a classification for each of the tokens that are output from verb, since we are labeling each one of them. Once the model is developed, we can use it to infer and put text to generate the labels and extract information. We will use the Nemo framework for its NLP capabilities. It uses high-level APIs for training custom models to simplify the development with pre-built modules. Furthermore, it supports a large catalog of pre-trained models. Technically, it uses a PyTorch Lightning back end for easy and performant, multi-GPU, multi-node, mixed-position training. Natural language processing requires a pipeline of operations even before model training. Using Nemo, we can leverage to pre-built modules to perform these operations, such as tokenization, position and betting, padding, attention masking, and others. This enables opportunities to develop custom token-net classification models for various use cases. When developing a token classification model, we can generally choose from several options. One, use out of the box models, two, fine tune and pre-trained model, three, train custom models from scratch. The decision is generally based on cost, which includes the cost of acquiring and labeling data, as well as a long training cycle. Let's now move over to the cloud instance and get started.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 5.0,
      "text": " In this module, we will discuss token classification.",
      "tokens": [
        50364,
        682,
        341,
        10088,
        11,
        321,
        486,
        2248,
        14862,
        21538,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15441027454946232,
      "compression_ratio": 1.7124463519313304,
      "no_speech_prob": 0.026054564863443375
    },
    {
      "id": 1,
      "seek": 0,
      "start": 5.0,
      "end": 8.0,
      "text": " Thanks to the advancements in language modeling,",
      "tokens": [
        50614,
        2561,
        281,
        264,
        7295,
        1117,
        294,
        2856,
        15983,
        11,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15441027454946232,
      "compression_ratio": 1.7124463519313304,
      "no_speech_prob": 0.026054564863443375
    },
    {
      "id": 2,
      "seek": 0,
      "start": 8.0,
      "end": 13.0,
      "text": " performing token classification has never been easier and more accurate.",
      "tokens": [
        50764,
        10205,
        14862,
        21538,
        575,
        1128,
        668,
        3571,
        293,
        544,
        8559,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15441027454946232,
      "compression_ratio": 1.7124463519313304,
      "no_speech_prob": 0.026054564863443375
    },
    {
      "id": 3,
      "seek": 0,
      "start": 13.0,
      "end": 16.0,
      "text": " In this module, you'll develop hands-on experience",
      "tokens": [
        51014,
        682,
        341,
        10088,
        11,
        291,
        603,
        1499,
        2377,
        12,
        266,
        1752,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15441027454946232,
      "compression_ratio": 1.7124463519313304,
      "no_speech_prob": 0.026054564863443375
    },
    {
      "id": 4,
      "seek": 0,
      "start": 16.0,
      "end": 19.0,
      "text": " with several variations of token classification.",
      "tokens": [
        51164,
        365,
        2940,
        17840,
        295,
        14862,
        21538,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15441027454946232,
      "compression_ratio": 1.7124463519313304,
      "no_speech_prob": 0.026054564863443375
    },
    {
      "id": 5,
      "seek": 0,
      "start": 19.0,
      "end": 23.0,
      "text": " We hope that will establish solid understanding of the development workflow",
      "tokens": [
        51314,
        492,
        1454,
        300,
        486,
        8327,
        5100,
        3701,
        295,
        264,
        3250,
        20993,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15441027454946232,
      "compression_ratio": 1.7124463519313304,
      "no_speech_prob": 0.026054564863443375
    },
    {
      "id": 6,
      "seek": 0,
      "start": 23.0,
      "end": 27.0,
      "text": " so that you can apply it to your own use cases.",
      "tokens": [
        51514,
        370,
        300,
        291,
        393,
        3079,
        309,
        281,
        428,
        1065,
        764,
        3331,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15441027454946232,
      "compression_ratio": 1.7124463519313304,
      "no_speech_prob": 0.026054564863443375
    },
    {
      "id": 7,
      "seek": 2700,
      "start": 28.0,
      "end": 32.0,
      "text": " At this time, I would like to ask you to click on the start button below.",
      "tokens": [
        50414,
        1711,
        341,
        565,
        11,
        286,
        576,
        411,
        281,
        1029,
        291,
        281,
        2052,
        322,
        264,
        722,
        2960,
        2507,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07974447385229246,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.00567022617906332
    },
    {
      "id": 8,
      "seek": 2700,
      "start": 32.0,
      "end": 36.0,
      "text": " This will assign a GPU accelerated cloud instance to you.",
      "tokens": [
        50614,
        639,
        486,
        6269,
        257,
        18407,
        29763,
        4588,
        5197,
        281,
        291,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07974447385229246,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.00567022617906332
    },
    {
      "id": 9,
      "seek": 2700,
      "start": 36.0,
      "end": 40.0,
      "text": " After the system installation and the configuration completes,",
      "tokens": [
        50814,
        2381,
        264,
        1185,
        13260,
        293,
        264,
        11694,
        36362,
        11,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07974447385229246,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.00567022617906332
    },
    {
      "id": 10,
      "seek": 2700,
      "start": 40.0,
      "end": 42.0,
      "text": " you'll be able to launch the hands-on lab.",
      "tokens": [
        51014,
        291,
        603,
        312,
        1075,
        281,
        4025,
        264,
        2377,
        12,
        266,
        2715,
        13,
        51114
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07974447385229246,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.00567022617906332
    },
    {
      "id": 11,
      "seek": 2700,
      "start": 42.0,
      "end": 46.0,
      "text": " In the meantime, let's preview what you'll learn.",
      "tokens": [
        51114,
        682,
        264,
        14991,
        11,
        718,
        311,
        14281,
        437,
        291,
        603,
        1466,
        13,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07974447385229246,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.00567022617906332
    },
    {
      "id": 12,
      "seek": 2700,
      "start": 46.0,
      "end": 50.0,
      "text": " This is a good visualization of what token classification can do",
      "tokens": [
        51314,
        639,
        307,
        257,
        665,
        25801,
        295,
        437,
        14862,
        21538,
        393,
        360,
        51514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07974447385229246,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.00567022617906332
    },
    {
      "id": 13,
      "seek": 2700,
      "start": 50.0,
      "end": 53.0,
      "text": " in the context of macro-language understanding.",
      "tokens": [
        51514,
        294,
        264,
        4319,
        295,
        18887,
        12,
        25241,
        20473,
        3701,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07974447385229246,
      "compression_ratio": 1.6,
      "no_speech_prob": 0.00567022617906332
    },
    {
      "id": 14,
      "seek": 5300,
      "start": 53.0,
      "end": 57.0,
      "text": " As an example, name entity recognition and ER,",
      "tokens": [
        50364,
        1018,
        364,
        1365,
        11,
        1315,
        13977,
        11150,
        293,
        14929,
        11,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12767327704080722,
      "compression_ratio": 1.6682692307692308,
      "no_speech_prob": 0.007871240377426147
    },
    {
      "id": 15,
      "seek": 5300,
      "start": 57.0,
      "end": 60.0,
      "text": " which is a kind of token classification,",
      "tokens": [
        50564,
        597,
        307,
        257,
        733,
        295,
        14862,
        21538,
        11,
        50714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12767327704080722,
      "compression_ratio": 1.6682692307692308,
      "no_speech_prob": 0.007871240377426147
    },
    {
      "id": 16,
      "seek": 5300,
      "start": 60.0,
      "end": 63.0,
      "text": " is used to identify specific entities in a text,",
      "tokens": [
        50714,
        307,
        1143,
        281,
        5876,
        2685,
        16667,
        294,
        257,
        2487,
        11,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12767327704080722,
      "compression_ratio": 1.6682692307692308,
      "no_speech_prob": 0.007871240377426147
    },
    {
      "id": 17,
      "seek": 5300,
      "start": 63.0,
      "end": 67.0,
      "text": " such as states, individuals, and places.",
      "tokens": [
        50864,
        1270,
        382,
        4368,
        11,
        5346,
        11,
        293,
        3190,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12767327704080722,
      "compression_ratio": 1.6682692307692308,
      "no_speech_prob": 0.007871240377426147
    },
    {
      "id": 18,
      "seek": 5300,
      "start": 67.0,
      "end": 70.0,
      "text": " Generally, token classification can transform",
      "tokens": [
        51064,
        21082,
        11,
        14862,
        21538,
        393,
        4088,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12767327704080722,
      "compression_ratio": 1.6682692307692308,
      "no_speech_prob": 0.007871240377426147
    },
    {
      "id": 19,
      "seek": 5300,
      "start": 70.0,
      "end": 75.0,
      "text": " unstructured text into structured data for more advanced text analytics.",
      "tokens": [
        51214,
        18799,
        46847,
        2487,
        666,
        18519,
        1412,
        337,
        544,
        7339,
        2487,
        15370,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12767327704080722,
      "compression_ratio": 1.6682692307692308,
      "no_speech_prob": 0.007871240377426147
    },
    {
      "id": 20,
      "seek": 5300,
      "start": 75.0,
      "end": 79.0,
      "text": " Token classification, like any ER and other tasks,",
      "tokens": [
        51464,
        314,
        8406,
        21538,
        11,
        411,
        604,
        14929,
        293,
        661,
        9608,
        11,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12767327704080722,
      "compression_ratio": 1.6682692307692308,
      "no_speech_prob": 0.007871240377426147
    },
    {
      "id": 21,
      "seek": 7900,
      "start": 79.0,
      "end": 82.0,
      "text": " are not just limited to these standard entities.",
      "tokens": [
        50364,
        366,
        406,
        445,
        5567,
        281,
        613,
        3832,
        16667,
        13,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.054987948617817445,
      "compression_ratio": 1.7227272727272727,
      "no_speech_prob": 0.005543909501284361
    },
    {
      "id": 22,
      "seek": 7900,
      "start": 82.0,
      "end": 87.0,
      "text": " They can be used to identify custom entities based on specific use cases.",
      "tokens": [
        50514,
        814,
        393,
        312,
        1143,
        281,
        5876,
        2375,
        16667,
        2361,
        322,
        2685,
        764,
        3331,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.054987948617817445,
      "compression_ratio": 1.7227272727272727,
      "no_speech_prob": 0.005543909501284361
    },
    {
      "id": 23,
      "seek": 7900,
      "start": 87.0,
      "end": 93.0,
      "text": " We can apply the approach to solve difficult problems quickly and efficiently.",
      "tokens": [
        50764,
        492,
        393,
        3079,
        264,
        3109,
        281,
        5039,
        2252,
        2740,
        2661,
        293,
        19621,
        13,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.054987948617817445,
      "compression_ratio": 1.7227272727272727,
      "no_speech_prob": 0.005543909501284361
    },
    {
      "id": 24,
      "seek": 7900,
      "start": 93.0,
      "end": 97.0,
      "text": " There are a lot of existing tools that perform token classification",
      "tokens": [
        51064,
        821,
        366,
        257,
        688,
        295,
        6741,
        3873,
        300,
        2042,
        14862,
        21538,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.054987948617817445,
      "compression_ratio": 1.7227272727272727,
      "no_speech_prob": 0.005543909501284361
    },
    {
      "id": 25,
      "seek": 7900,
      "start": 97.0,
      "end": 100.0,
      "text": " with varying degrees of performance.",
      "tokens": [
        51264,
        365,
        22984,
        5310,
        295,
        3389,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.054987948617817445,
      "compression_ratio": 1.7227272727272727,
      "no_speech_prob": 0.005543909501284361
    },
    {
      "id": 26,
      "seek": 7900,
      "start": 100.0,
      "end": 105.0,
      "text": " They can also be limited in the type of classification they can perform.",
      "tokens": [
        51414,
        814,
        393,
        611,
        312,
        5567,
        294,
        264,
        2010,
        295,
        21538,
        436,
        393,
        2042,
        13,
        51664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.054987948617817445,
      "compression_ratio": 1.7227272727272727,
      "no_speech_prob": 0.005543909501284361
    },
    {
      "id": 27,
      "seek": 10500,
      "start": 105.0,
      "end": 108.0,
      "text": " So, to truly enable token classification,",
      "tokens": [
        50364,
        407,
        11,
        281,
        4908,
        9528,
        14862,
        21538,
        11,
        50514
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07170593610373877,
      "compression_ratio": 1.7440758293838863,
      "no_speech_prob": 0.009882885031402111
    },
    {
      "id": 28,
      "seek": 10500,
      "start": 108.0,
      "end": 111.0,
      "text": " we need a process that can be generalized.",
      "tokens": [
        50514,
        321,
        643,
        257,
        1399,
        300,
        393,
        312,
        44498,
        13,
        50664
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07170593610373877,
      "compression_ratio": 1.7440758293838863,
      "no_speech_prob": 0.009882885031402111
    },
    {
      "id": 29,
      "seek": 10500,
      "start": 111.0,
      "end": 114.0,
      "text": " The first token classification model will use",
      "tokens": [
        50664,
        440,
        700,
        14862,
        21538,
        2316,
        486,
        764,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07170593610373877,
      "compression_ratio": 1.7440758293838863,
      "no_speech_prob": 0.009882885031402111
    },
    {
      "id": 30,
      "seek": 10500,
      "start": 114.0,
      "end": 118.0,
      "text": " consists of a verb model plus a classification layer.",
      "tokens": [
        50814,
        14689,
        295,
        257,
        9595,
        2316,
        1804,
        257,
        21538,
        4583,
        13,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07170593610373877,
      "compression_ratio": 1.7440758293838863,
      "no_speech_prob": 0.009882885031402111
    },
    {
      "id": 31,
      "seek": 10500,
      "start": 118.0,
      "end": 122.0,
      "text": " In this case, we'll need a classification for each of the tokens",
      "tokens": [
        51014,
        682,
        341,
        1389,
        11,
        321,
        603,
        643,
        257,
        21538,
        337,
        1184,
        295,
        264,
        22667,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07170593610373877,
      "compression_ratio": 1.7440758293838863,
      "no_speech_prob": 0.009882885031402111
    },
    {
      "id": 32,
      "seek": 10500,
      "start": 122.0,
      "end": 124.0,
      "text": " that are output from verb,",
      "tokens": [
        51214,
        300,
        366,
        5598,
        490,
        9595,
        11,
        51314
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07170593610373877,
      "compression_ratio": 1.7440758293838863,
      "no_speech_prob": 0.009882885031402111
    },
    {
      "id": 33,
      "seek": 10500,
      "start": 124.0,
      "end": 127.0,
      "text": " since we are labeling each one of them.",
      "tokens": [
        51314,
        1670,
        321,
        366,
        40244,
        1184,
        472,
        295,
        552,
        13,
        51464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07170593610373877,
      "compression_ratio": 1.7440758293838863,
      "no_speech_prob": 0.009882885031402111
    },
    {
      "id": 34,
      "seek": 10500,
      "start": 127.0,
      "end": 130.0,
      "text": " Once the model is developed, we can use it to infer",
      "tokens": [
        51464,
        3443,
        264,
        2316,
        307,
        4743,
        11,
        321,
        393,
        764,
        309,
        281,
        13596,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07170593610373877,
      "compression_ratio": 1.7440758293838863,
      "no_speech_prob": 0.009882885031402111
    },
    {
      "id": 35,
      "seek": 13000,
      "start": 130.0,
      "end": 135.0,
      "text": " and put text to generate the labels and extract information.",
      "tokens": [
        50364,
        293,
        829,
        2487,
        281,
        8460,
        264,
        16949,
        293,
        8947,
        1589,
        13,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12886566701142685,
      "compression_ratio": 1.5084033613445378,
      "no_speech_prob": 0.01482095941901207
    },
    {
      "id": 36,
      "seek": 13000,
      "start": 135.0,
      "end": 139.0,
      "text": " We will use the Nemo framework for its NLP capabilities.",
      "tokens": [
        50614,
        492,
        486,
        764,
        264,
        22210,
        78,
        8388,
        337,
        1080,
        426,
        45196,
        10862,
        13,
        50814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12886566701142685,
      "compression_ratio": 1.5084033613445378,
      "no_speech_prob": 0.01482095941901207
    },
    {
      "id": 37,
      "seek": 13000,
      "start": 139.0,
      "end": 143.0,
      "text": " It uses high-level APIs for training custom models",
      "tokens": [
        50814,
        467,
        4960,
        1090,
        12,
        12418,
        21445,
        337,
        3097,
        2375,
        5245,
        51014
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12886566701142685,
      "compression_ratio": 1.5084033613445378,
      "no_speech_prob": 0.01482095941901207
    },
    {
      "id": 38,
      "seek": 13000,
      "start": 143.0,
      "end": 146.0,
      "text": " to simplify the development with pre-built modules.",
      "tokens": [
        51014,
        281,
        20460,
        264,
        3250,
        365,
        659,
        12,
        23018,
        16679,
        13,
        51164
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12886566701142685,
      "compression_ratio": 1.5084033613445378,
      "no_speech_prob": 0.01482095941901207
    },
    {
      "id": 39,
      "seek": 13000,
      "start": 146.0,
      "end": 151.0,
      "text": " Furthermore, it supports a large catalog of pre-trained models.",
      "tokens": [
        51164,
        23999,
        11,
        309,
        9346,
        257,
        2416,
        19746,
        295,
        659,
        12,
        17227,
        2001,
        5245,
        13,
        51414
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12886566701142685,
      "compression_ratio": 1.5084033613445378,
      "no_speech_prob": 0.01482095941901207
    },
    {
      "id": 40,
      "seek": 13000,
      "start": 151.0,
      "end": 155.0,
      "text": " Technically, it uses a PyTorch Lightning back end",
      "tokens": [
        51414,
        42494,
        11,
        309,
        4960,
        257,
        9953,
        51,
        284,
        339,
        28848,
        646,
        917,
        51614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12886566701142685,
      "compression_ratio": 1.5084033613445378,
      "no_speech_prob": 0.01482095941901207
    },
    {
      "id": 41,
      "seek": 13000,
      "start": 155.0,
      "end": 157.0,
      "text": " for easy and performant,",
      "tokens": [
        51614,
        337,
        1858,
        293,
        2042,
        394,
        11,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12886566701142685,
      "compression_ratio": 1.5084033613445378,
      "no_speech_prob": 0.01482095941901207
    },
    {
      "id": 42,
      "seek": 15700,
      "start": 157.0,
      "end": 161.0,
      "text": " multi-GPU, multi-node, mixed-position training.",
      "tokens": [
        50364,
        4825,
        12,
        38,
        8115,
        11,
        4825,
        12,
        77,
        1429,
        11,
        7467,
        12,
        38078,
        3097,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19240334328640712,
      "compression_ratio": 1.6277056277056277,
      "no_speech_prob": 0.0008935992955230176
    },
    {
      "id": 43,
      "seek": 15700,
      "start": 161.0,
      "end": 165.0,
      "text": " Natural language processing requires a pipeline of operations",
      "tokens": [
        50564,
        20137,
        2856,
        9007,
        7029,
        257,
        15517,
        295,
        7705,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19240334328640712,
      "compression_ratio": 1.6277056277056277,
      "no_speech_prob": 0.0008935992955230176
    },
    {
      "id": 44,
      "seek": 15700,
      "start": 165.0,
      "end": 167.0,
      "text": " even before model training.",
      "tokens": [
        50764,
        754,
        949,
        2316,
        3097,
        13,
        50864
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19240334328640712,
      "compression_ratio": 1.6277056277056277,
      "no_speech_prob": 0.0008935992955230176
    },
    {
      "id": 45,
      "seek": 15700,
      "start": 167.0,
      "end": 171.0,
      "text": " Using Nemo, we can leverage to pre-built modules",
      "tokens": [
        50864,
        11142,
        22210,
        78,
        11,
        321,
        393,
        13982,
        281,
        659,
        12,
        23018,
        16679,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19240334328640712,
      "compression_ratio": 1.6277056277056277,
      "no_speech_prob": 0.0008935992955230176
    },
    {
      "id": 46,
      "seek": 15700,
      "start": 171.0,
      "end": 175.0,
      "text": " to perform these operations, such as tokenization,",
      "tokens": [
        51064,
        281,
        2042,
        613,
        7705,
        11,
        1270,
        382,
        14862,
        2144,
        11,
        51264
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19240334328640712,
      "compression_ratio": 1.6277056277056277,
      "no_speech_prob": 0.0008935992955230176
    },
    {
      "id": 47,
      "seek": 15700,
      "start": 175.0,
      "end": 181.0,
      "text": " position and betting, padding, attention masking, and others.",
      "tokens": [
        51264,
        2535,
        293,
        34246,
        11,
        39562,
        11,
        3202,
        31226,
        11,
        293,
        2357,
        13,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19240334328640712,
      "compression_ratio": 1.6277056277056277,
      "no_speech_prob": 0.0008935992955230176
    },
    {
      "id": 48,
      "seek": 15700,
      "start": 181.0,
      "end": 186.0,
      "text": " This enables opportunities to develop custom token-net classification models",
      "tokens": [
        51564,
        639,
        17077,
        4786,
        281,
        1499,
        2375,
        14862,
        12,
        7129,
        21538,
        5245,
        51814
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19240334328640712,
      "compression_ratio": 1.6277056277056277,
      "no_speech_prob": 0.0008935992955230176
    },
    {
      "id": 49,
      "seek": 18600,
      "start": 186.0,
      "end": 188.0,
      "text": " for various use cases.",
      "tokens": [
        50364,
        337,
        3683,
        764,
        3331,
        13,
        50464
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09779017022315492,
      "compression_ratio": 1.5964125560538116,
      "no_speech_prob": 0.0019248216412961483
    },
    {
      "id": 50,
      "seek": 18600,
      "start": 188.0,
      "end": 191.0,
      "text": " When developing a token classification model,",
      "tokens": [
        50464,
        1133,
        6416,
        257,
        14862,
        21538,
        2316,
        11,
        50614
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09779017022315492,
      "compression_ratio": 1.5964125560538116,
      "no_speech_prob": 0.0019248216412961483
    },
    {
      "id": 51,
      "seek": 18600,
      "start": 191.0,
      "end": 194.0,
      "text": " we can generally choose from several options.",
      "tokens": [
        50614,
        321,
        393,
        5101,
        2826,
        490,
        2940,
        3956,
        13,
        50764
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09779017022315492,
      "compression_ratio": 1.5964125560538116,
      "no_speech_prob": 0.0019248216412961483
    },
    {
      "id": 52,
      "seek": 18600,
      "start": 194.0,
      "end": 197.0,
      "text": " One, use out of the box models,",
      "tokens": [
        50764,
        1485,
        11,
        764,
        484,
        295,
        264,
        2424,
        5245,
        11,
        50914
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09779017022315492,
      "compression_ratio": 1.5964125560538116,
      "no_speech_prob": 0.0019248216412961483
    },
    {
      "id": 53,
      "seek": 18600,
      "start": 197.0,
      "end": 200.0,
      "text": " two, fine tune and pre-trained model,",
      "tokens": [
        50914,
        732,
        11,
        2489,
        10864,
        293,
        659,
        12,
        17227,
        2001,
        2316,
        11,
        51064
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09779017022315492,
      "compression_ratio": 1.5964125560538116,
      "no_speech_prob": 0.0019248216412961483
    },
    {
      "id": 54,
      "seek": 18600,
      "start": 200.0,
      "end": 203.0,
      "text": " three, train custom models from scratch.",
      "tokens": [
        51064,
        1045,
        11,
        3847,
        2375,
        5245,
        490,
        8459,
        13,
        51214
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09779017022315492,
      "compression_ratio": 1.5964125560538116,
      "no_speech_prob": 0.0019248216412961483
    },
    {
      "id": 55,
      "seek": 18600,
      "start": 203.0,
      "end": 206.0,
      "text": " The decision is generally based on cost,",
      "tokens": [
        51214,
        440,
        3537,
        307,
        5101,
        2361,
        322,
        2063,
        11,
        51364
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09779017022315492,
      "compression_ratio": 1.5964125560538116,
      "no_speech_prob": 0.0019248216412961483
    },
    {
      "id": 56,
      "seek": 18600,
      "start": 206.0,
      "end": 210.0,
      "text": " which includes the cost of acquiring and labeling data,",
      "tokens": [
        51364,
        597,
        5974,
        264,
        2063,
        295,
        37374,
        293,
        40244,
        1412,
        11,
        51564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09779017022315492,
      "compression_ratio": 1.5964125560538116,
      "no_speech_prob": 0.0019248216412961483
    },
    {
      "id": 57,
      "seek": 18600,
      "start": 210.0,
      "end": 213.0,
      "text": " as well as a long training cycle.",
      "tokens": [
        51564,
        382,
        731,
        382,
        257,
        938,
        3097,
        6586,
        13,
        51714
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09779017022315492,
      "compression_ratio": 1.5964125560538116,
      "no_speech_prob": 0.0019248216412961483
    },
    {
      "id": 58,
      "seek": 21300,
      "start": 213.0,
      "end": 217.0,
      "text": " Let's now move over to the cloud instance and get started.",
      "tokens": [
        50364,
        961,
        311,
        586,
        1286,
        670,
        281,
        264,
        4588,
        5197,
        293,
        483,
        1409,
        13,
        50564
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1229950487613678,
      "compression_ratio": 0.9206349206349206,
      "no_speech_prob": 0.02380530908703804
    }
  ],
  "language": "en"
}